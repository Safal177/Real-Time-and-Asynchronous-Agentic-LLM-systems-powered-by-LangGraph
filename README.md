# Real-Time-and-Asynchronous-Agentic-LLM-systems-powered-by-LangGraph

# Experimental title:
Streaming and Non-Streaming Agentic LLM workflows with Tool integration using LangGraph

# Primary goal:
The main goal of this project is to make an Agentic LLM pipeline. When running this pipeline, it supports the following facts.
•	Connect outside tools such web search to LLM thought process.
•	Use LangGraph to facilitate context as well as tool optimized agent operation.
•	Accommodate both streaming and non-streaming processing modes.
•	Present real-time results gathering for most recent user queries.
•	Show how to make operational LLM pipelines.

# System components
•	Jupyter Notebook (Python)                                                                                                                      
•	LangGraph | LangChain
•	LLM (gpt-4o-mini) | Tavily search api 
•	Agentic AI frameworks
•	Streaming | non-streaming LLM Inference
•	Query configuration

# Main Features:
•	Agentic LLM configuration with tools.
•	Agentic process pipeline with LangGraph.
•	Streaming and non-streaming Agentic mode. 
•	Situational tool engagement. 
•	Coordinating conversation state.
•	Real world query interpretation.

# Project file:
Advanced_LLM_Tool_Embedding_LangGraph.jpynb

